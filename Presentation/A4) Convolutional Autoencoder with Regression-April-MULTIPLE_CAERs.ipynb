{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import cv2\n",
    "\n",
    "# Clustering\n",
    "from sklearn.cluster import AgglomerativeClustering # 1) Agglomerative-Hierarchical\n",
    "from sklearn.cluster import KMeans                  # 2) K-Means\n",
    "from sklearn.mixture import GaussianMixture         # 3) Gaussian Mixture Models\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, GridSearchCV\n",
    "# Evaluation\n",
    "from sklearn import metrics\n",
    "from skimage.external import tifffile\n",
    "from skimage.measure import compare_mse\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "from sklearn.decomposition import PCA, KernelPCA               # 2) PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Load Autoencoder                                  # 3) Autoencoder (Deep dimensionality reduction)\n",
    "from keras.models import load_model\n",
    "from keras.models import Model\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "\n",
    "import newscripts as myutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pltPathologyClusters(labels, path):\n",
    "    sub_directories = [str(cluster) for cluster in set(labels)]\n",
    "    displayImages = []\n",
    "    fig = plt.figure(figsize=(14, 14))\n",
    "    \n",
    "    x=1\n",
    "    \n",
    "    for cluster in sub_directories:\n",
    "        direct = path + '/{}'.format(cluster)\n",
    "        if len(os.listdir(direct))-9 > 9: # if directory has less than 9 images set index to 0 else random index\n",
    "            index = np.random.randint(9,len(os.listdir(direct))-9)\n",
    "        else:\n",
    "            index = 0 # pick the first 10 images\n",
    "        clusterList = [] # reset the row\n",
    "        for file in os.listdir(direct)[index:index+9]: # random sample of 9 images\n",
    "            if file.endswith('.tif'):\n",
    "                image = tifffile.imread(os.path.join(path, file))\n",
    "                clusterList.append(image)\n",
    "                displayImages.append(image) # list of ALL Images\n",
    "                \n",
    "        for i in range(1,9+1):\n",
    "            if (len(clusterList) > i):\n",
    "                img = clusterList[i-1]\n",
    "            fig.add_subplot(8, 9, x)\n",
    "            plt.imshow(img)\n",
    "            plt.axis('off')\n",
    "            plt.subplots_adjust(wspace=0.0, hspace=0.0)\n",
    "            x+=1\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "def symlink_rel(src, dst):\n",
    "    rel_path_src = os.path.relpath(src, os.path.dirname(dst))\n",
    "    os.symlink(rel_path_src, dst)\n",
    "    \n",
    "def clusterintoDirectories(labels, path, imagenamesList):\n",
    "    # remove existing subdirectories first to avoid overlap\n",
    "    sub_directories = [str(i) for i in range(8)]\n",
    "\n",
    "    for cluster in sub_directories:\n",
    "        if (cluster in os.listdir(path)) and (os.path.isdir(os.path.join(path , cluster))):\n",
    "            shutil.rmtree(os.path.join(path , cluster))\n",
    "\n",
    "    for filename in os.listdir(path):\n",
    "        if filename.endswith('.tif'):\n",
    "            for cluster in sub_directories: # count of distinct elements = no. of clusters\n",
    "                os.makedirs(path + '/{}'.format(cluster) , exist_ok=True)\n",
    "    \n",
    "    for i in range(len(imagenamesList)):\n",
    "        if imagenamesList[i] not in os.listdir(path + '/' + sub_directories[labels[i]]): \n",
    "            symlink_rel(path + '/{}'.format(imagenamesList[i]) , \n",
    "                       path + '/{}'.format(labels[i]) + '/' + imagenamesList[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kather\n",
    "# Load training data\n",
    "\n",
    "train_directory = \"../../Data/Kather_all_train\"\n",
    "\n",
    "X_train = []\n",
    "train_image_names = []\n",
    "\n",
    "for filename in os.listdir(train_directory):\n",
    "    if filename.endswith('tif'):\n",
    "        image = cv2.imread(os.path.join(train_directory, filename), cv2.IMREAD_UNCHANGED)\n",
    "        resized_image = cv2.resize(image, (96, 96)) \n",
    "        X_train.append(np.asarray( resized_image, dtype=\"uint8\" ))\n",
    "        train_image_names.append(filename)\n",
    "\n",
    "y_train = myutils.loadLabelsFromsubdirectoryindex(train_image_names, \"../../Data/Kather_original_train\")\n",
    "\n",
    "# Load testing data\n",
    "\n",
    "test_directory = \"../../Data/Kather_all_test\"\n",
    "\n",
    "X_test = []\n",
    "test_image_names = []\n",
    "\n",
    "for filename in os.listdir(test_directory):\n",
    "    if filename.endswith('tif'):\n",
    "        image = cv2.imread(os.path.join(test_directory, filename), cv2.IMREAD_UNCHANGED)\n",
    "        resized_image = cv2.resize(image, (96, 96)) \n",
    "        X_test.append(np.asarray( resized_image, dtype=\"uint8\" ))\n",
    "        test_image_names.append(filename)\n",
    "\n",
    "y_test = myutils.loadLabelsFromsubdirectoryindex(test_image_names, \"../../Data/Kather_original_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.asarray(X_train)\n",
    "X_test = np.asarray(X_test)\n",
    "\n",
    "# Normalise\n",
    "X_train = X_train.astype('float32') / 255.\n",
    "X_test = X_test.astype('float32') / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotdiffTsne(X):\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(13, 7))\n",
    "\n",
    "    tsne2 = TSNE(n_components=2, perplexity = 30).fit_transform(X)\n",
    "    kmeans2 = KMeans(algorithm='auto', copy_x=True, init='random', max_iter=300, n_clusters=8,\n",
    "       n_init=10, n_jobs=None, precompute_distances='auto', random_state=19,\n",
    "       tol=0.0001, verbose=0).fit(tsne2)\n",
    "\n",
    "    axs[0, 1].scatter(tsne2[:, 0], tsne2[:, 1], c=kmeans2.labels_, cmap='viridis')\n",
    "    axs[0, 1].set_title('TSNE perplexity = 30')\n",
    "\n",
    "    tsne4 = TSNE(n_components=2, perplexity = 90).fit_transform(X)\n",
    "    kmeans4 = KMeans(algorithm='auto', copy_x=True, init='random', max_iter=300, n_clusters=8,\n",
    "       n_init=10, n_jobs=None, precompute_distances='auto', random_state=19,\n",
    "       tol=0.0001, verbose=0).fit(tsne4)\n",
    "\n",
    "    axs[1, 1].scatter(tsne4[:, 0], tsne4[:, 1], c=kmeans4.labels_, cmap='viridis')\n",
    "    axs[1, 1].set_title('TSNE perplexity = 90')\n",
    "    \n",
    "    plt.savefig('TSNE-CAE.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "CAESSIM_Kather_16 = load_model('../Autoencoders/SavedModels/weights/CAE-SSIM/23FebruarySSIM_epochs1000_batch16_adam.h5', compile=False)\n",
    "encoder = Model(inputs=CAESSIM_Kather_16.input, outputs=CAESSIM_Kather_16.get_layer('conv2d_7').output)\n",
    "# CAESSIM_Kather_16.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "CAER_MSE_Kaggle_32 = load_model('../Autoencoders/SavedModels/weights/CAER-MSE-Kaggle/epochs300_batch64_0.6023092042605083.h5')\n",
    "encoder = Model(inputs=CAER_MSE_Kaggle_32.input, outputs=CAER_MSE_Kaggle_32.get_layer('conv2d_103').output)\n",
    "# CAER_MSE_Kaggle_32.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-1236368e5cea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlabels_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCAER_MSE_Kaggle_32\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlabels_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mlabels_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1460\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1461\u001b[0m                                             \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1462\u001b[0;31m                                             callbacks=callbacks)\n\u001b[0m\u001b[1;32m   1463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1464\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps, callbacks)\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0mbatch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'batch'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'size'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'predict'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'begin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3725\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3726\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3727\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3729\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1549\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1550\u001b[0m     \"\"\"\n\u001b[0;32m-> 1551\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1553\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1589\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1590\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1591\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1593\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def evaluate_two_classes(model, data, labels_pred, truelabels):\n",
    "    labels_pred = model.predict(data)[1]\n",
    "    for i in range(len(labels_pred)):\n",
    "        if labels_pred[i] < 0.5:\n",
    "            labels_pred[i] = 0\n",
    "        else:\n",
    "            labels_pred[i] = 1\n",
    "\n",
    "    print(metrics.classification_report(truelabels,labels_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder3 = load_model('../Autoencoders/SavedModels/new_mean_squared_error_epochs300_batch64.h5')\n",
    "# encoder = Model(inputs=autoencoder.input, outputs=autoencoder.get_layer(layer_name).output)\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4200, 6, 6, 32)\n"
     ]
    }
   ],
   "source": [
    "X_train_enc = encoder.predict(X_train)\n",
    "print(X_train_enc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 96, 96, 3)\n"
     ]
    }
   ],
   "source": [
    "X_test_enc = encoder.predict(X_test)\n",
    "print(X_test.shape)\n",
    "\n",
    "X_train_enc = X_train_enc.reshape(X_train_enc.shape[0] , -1) # Reshape for scaling\n",
    "X_train_enc = StandardScaler().fit_transform(X_train_enc) # Scale\n",
    "\n",
    "X_test_enc = X_test_enc.reshape(X_test_enc.shape[0] , -1) # Reshape for scaling\n",
    "X_test_enc = StandardScaler().fit_transform(X_test_enc) # Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianMixture(covariance_type='diag', init_params='kmeans', max_iter=100,\n",
      "                means_init=None, n_components=8, n_init=1, precisions_init=None,\n",
      "                random_state=19, reg_covar=1e-06, tol=0.001, verbose=0,\n",
      "                verbose_interval=10, warm_start=False, weights_init=None)\n",
      "0.542857335581645\n",
      "KMeans(algorithm='auto', copy_x=True, init='random', max_iter=300, n_clusters=8,\n",
      "       n_init=10, n_jobs=None, precompute_distances='auto', random_state=19,\n",
      "       tol=0.0001, verbose=0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5259470165110727"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate on testing data using grid search  cv\n",
    "parameters = {'covariance_type':('full', 'spherical', 'diag', 'tied'), 'n_components':[8],'random_state':[0,19,42]}\n",
    "clf = GridSearchCV(GaussianMixture(), parameters, scoring=make_scorer(metrics.completeness_score))\n",
    "\n",
    "clf.fit(X_train_enc, y_train)\n",
    "print(clf.best_estimator_)\n",
    "print(clf.best_score_)\n",
    "\n",
    "parameters = {'init':('k-means++', 'random'), 'n_clusters':[8],'random_state':[0,19,42]}\n",
    "clf2 = GridSearchCV(KMeans(), parameters, scoring=make_scorer(metrics.completeness_score))\n",
    "\n",
    "clf2.fit(X_train_enc, y_train)\n",
    "print(clf2.best_estimator_)\n",
    "clf2.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.902913327794522\n",
      "0.9299359017750248\n"
     ]
    }
   ],
   "source": [
    "# PCA \n",
    "# Reduce Dimensions\n",
    "# PCA \n",
    "pca1 = PCA(n_components=150)\n",
    "transformed_train = pca1.fit_transform(X_train_enc)\n",
    "\n",
    "pca2 = PCA(n_components=150)\n",
    "transformed_test = pca2.fit_transform(X_test_enc)\n",
    "\n",
    "print(sum(pca1.explained_variance_ratio_))\n",
    "print(sum(pca2.explained_variance_ratio_))\n",
    "# print(pca1.n_components_)\n",
    "# pca2.n_components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9701810850820038\n",
      "0.9857587999867974\n"
     ]
    }
   ],
   "source": [
    "# PCA \n",
    "# Reduce Dimensions\n",
    "# PCA \n",
    "pca1 = PCA(n_components=300)\n",
    "transformed_train = pca1.fit_transform(X_train_enc)\n",
    "\n",
    "pca2 = PCA(n_components=300)\n",
    "transformed_test = pca2.fit_transform(X_test_enc)\n",
    "\n",
    "print(sum(pca1.explained_variance_ratio_))\n",
    "print(sum(pca2.explained_variance_ratio_))\n",
    "# print(pca1.n_components_)\n",
    "# pca2.n_components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotdiffTsne(transformed_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
